{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "phxyrevocepyrxwxn5sj",
   "authorId": "7281864487759",
   "authorName": "SOSTROWSKI",
   "authorEmail": "savannah.ostrowski@snowflake.com",
   "sessionId": "1a38f72a-620b-466b-8959-9b43ba147d76",
   "lastEditTime": 1744990445175
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "connection"
   },
   "source": "# Connect to your data instantly with Snowpark\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f803415b-ae24-4531-9e43-d820cc15420b",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.version import VERSION\nfrom snowflake.snowpark.functions import udf\nimport snowflake.snowpark.functions as F\n\nfrom snowflake.ml.modeling.xgboost import XGBRegressor\nfrom snowflake.ml.modeling.model_selection import GridSearchCV\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml._internal.utils import identifier\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom snowflake.ml.modeling.metrics import mean_absolute_percentage_error\n\nimport json\nimport joblib\nimport cachetools\nimport warnings; warnings.simplefilter('ignore')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "441ceeb7-bda3-417e-a999-7830ec4088ae",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "diamonds_df = session.read.table('SAVANNAH_TEST.SAVANNAH_TEST.DIAMONDS')\n\ndiamonds_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58ca18e0-fc4b-481c-b29d-ae169e3f1154",
   "metadata": {
    "language": "sql",
    "name": "avg_price_per_cut"
   },
   "outputs": [],
   "source": "SELECT\n  cut,\n  AVG(price) as avg_price\nFROM\n  SAVANNAH_TEST.SAVANNAH_TEST.DIAMONDS\nGROUP BY\n  cut;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ab10d010-3a81-444b-862e-c01404c8192f",
   "metadata": {
    "language": "python",
    "name": "max_avg_price"
   },
   "outputs": [],
   "source": "cut_price_df = avg_price_per_cut.to_pandas()\nmax_price = cut_price_df['AVG_PRICE'].max()\nprint(f\"Maximum average price: ${max_price:,.2f}\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "89dac6cb-0c4d-4444-a699-249896f879e7",
   "metadata": {
    "language": "python",
    "name": "price_max"
   },
   "outputs": [],
   "source": "price_threshold = 2000",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d26b226-97b8-4e65-9d55-16ae2a2c9300",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "outputs": [],
   "source": "SELECT\n  cut,\n  COUNT(*) as diamond_count\nFROM\n  SAVANNAH_TEST.SAVANNAH_TEST.DIAMONDS\nWHERE\n  price > {{price_threshold}}\nGROUP BY\n  cut;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e3481899-af8e-4486-9f22-89b7cb868faf",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "import streamlit as st\nimport altair as alt\n\ndf = diamonds_df.to_pandas()\n\nst.title(\"Diamond Carat vs Price Analysis\")\n\nchart = alt.Chart(df).mark_circle().encode(\n    x='CARAT',\n    y='PRICE',\n    color='CUT',\n    tooltip=['CARAT', 'PRICE', 'CUT', 'COLOR']\n).properties(\n    width=600,\n    height=400\n)\n\nst.altair_chart(chart, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82c49965-1cad-4811-9d4b-df57b951a87e",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "import streamlit as st\nimport altair as alt\n\n# Cache the data loading\n@st.cache_data\ndef load_data():\n    return diamonds_df.to_pandas()\n\n# Load the data using the cached function\ndf = load_data()\n\nst.title(\"Diamond Analysis Dashboard\")\n\n# Create metrics for quick statistics\ncol1, col2, col3 = st.columns(3)\nwith col1:\n    st.metric(\"Average Price\", f\"${df['PRICE'].mean():,.2f}\")\nwith col2:\n    st.metric(\"Average Carat\", f\"{df['CARAT'].mean():.2f}\")\nwith col3:\n    st.metric(\"Price Range\", f\"${df['PRICE'].min():,} - ${df['PRICE'].max():,}\")\n\n# Create filters\ncol1, col2 = st.columns(2)\nwith col1:\n    cut_selection = st.multiselect(\"Select Cut\", \n                                 options=sorted(df['CUT'].unique()), \n                                 default=sorted(df['CUT'].unique()))\nwith col2:\n    color_selection = st.multiselect(\"Select Color\", \n                                   options=sorted(df['COLOR'].unique()), \n                                   default=sorted(df['COLOR'].unique()))\n\nprice_range = st.slider(\"Price Range\", \n                       min_value=int(df['PRICE'].min()), \n                       max_value=int(df['PRICE'].max()),\n                       value=(int(df['PRICE'].min()), int(df['PRICE'].max())))\n\n# Cache the filtering operation\n@st.cache_data\ndef filter_data(df, cuts, colors, price_min, price_max):\n    return df[\n        (df['CUT'].isin(cuts)) &\n        (df['COLOR'].isin(colors)) &\n        (df['PRICE'].between(price_min, price_max))\n    ]\n\n# Apply filters using cached function\nfiltered_df = filter_data(df, cut_selection, color_selection, price_range[0], price_range[1])\n\n# Create visualizations\ncol1, col2 = st.columns(2)\n\nwith col1:\n    st.subheader(\"Price Distribution by Cut\")\n    chart1 = alt.Chart(filtered_df).mark_boxplot().encode(\n        x='CUT:N',\n        y='PRICE:Q',\n        color='CUT:N'\n    ).properties(height=300)\n    st.altair_chart(chart1, use_container_width=True)\n\nwith col2:\n    st.subheader(\"Carat vs Price\")\n    chart2 = alt.Chart(filtered_df).mark_circle().encode(\n        x='CARAT:Q',\n        y='PRICE:Q',\n        color='CUT:N',\n        tooltip=['CUT', 'COLOR', 'PRICE', 'CARAT']\n    ).properties(height=300)\n    st.altair_chart(chart2, use_container_width=True)\n\n# Show average price by cut and color\nst.subheader(\"Average Price by Cut and Color\")\navg_price_chart = alt.Chart(filtered_df).mark_rect().encode(\n    x='CUT:N',\n    y='COLOR:N',\n    color=alt.Color('mean(PRICE):Q', scale=alt.Scale(scheme='viridis')),\n    tooltip=['CUT', 'COLOR', alt.Tooltip('mean(PRICE):Q', format='$,.2f')]\n).properties(height=200)\nst.altair_chart(avg_price_chart, use_container_width=True)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "46d7e857-fde5-4e71-9fb7-66212b33e589",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "session.query_tag = {\"origin\":\"sf_sit-is\", \n                     \"name\":\"e2e_ml_snowparkpython\", \n                     \"version\":{\"major\":1, \"minor\":0,},\n                     \"attributes\":{\"is_quickstart\":1}}\nsession",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eb36ccef-39e9-4c1b-adac-9f9b5ecfe216",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "# Feature Transformations\nWe will illustrate a few of the transformation functions here, but the rest can be found in the documentation.\n\nLet's use the MinMaxScaler to normalize the CARAT column."
  },
  {
   "cell_type": "code",
   "id": "158a35f4-addb-47b9-860a-f8f1a8d28ad8",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "# Normalize the CARAT column\nsnowml_mms = snowml.MinMaxScaler(input_cols=[\"CARAT\"], output_cols=[\"CARAT_NORM\"])\nnormalized_diamonds_df = snowml_mms.fit(diamonds_df).transform(diamonds_df)\n\n# Reduce the number of decimals\nnew_col = normalized_diamonds_df.col(\"CARAT_NORM\").cast(DecimalType(7, 6))\nnormalized_diamonds_df = normalized_diamonds_df.with_column(\"CARAT_NORM\", new_col)\n\nnormalized_diamonds_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "22743ad2-ebe1-4b45-9bc2-4f84ac8ab6f9",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "Let's use the OrdinalEncoder to transform COLOR and CLARITY from categorical to numerical values so they are more meaningful."
  },
  {
   "cell_type": "code",
   "id": "d15990d5-1c2b-4167-9e8f-0043384de275",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "# Encode CUT and CLARITY preserve ordinal importance\ncategories = {\n    \"CUT\": np.array([\"Fair\", \"Good\", \"Very Good\", \"Premium\", \"Ideal\"]),\n    \"CLARITY\": np.array([\"IF\", \"VVS1\", \"VVS2\", \"VS1\", \"VS2\", \"SI1\", \"SI2\", \"I1\", \"I2\", \"I3\"]),\n}\n\nsnowml_oe = snowml.OrdinalEncoder(\n    input_cols=[\"CUT\", \"CLARITY\"], \n    output_cols=[\"CUT_OE\", \"CLARITY_OE\"], \n    categories=categories\n)\n\nord_encoded_diamonds_df = snowml_oe.fit(normalized_diamonds_df).transform(normalized_diamonds_df)\n\n# Show the encoding\nprint(snowml_oe._state_pandas)\n\nord_encoded_diamonds_df\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5ca5e4b1-b135-4926-9bf4-d4776d6003d4",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "Let's use the OneHotEncoder to transform the categorical columns to numerical columns.\nThis is more for illustration purposes. Using the OrdinalEncoder makes more sense for the diamonds dataset since CARAT, COLOR, and CLARITY all follow a natural ranking order."
  },
  {
   "cell_type": "code",
   "id": "31f47e05-6c96-4d04-aa7b-e40d7e32000c",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "# Encode categoricals to numeric columns\nsnowml_ohe = snowml.OneHotEncoder(input_cols=[\"CUT\", \"COLOR\", \"CLARITY\"], output_cols=[\"CUT_OHE\", \"COLOR_OHE\", \"CLARITY_OHE\"])\ntransformed_diamonds_df = snowml_ohe.fit(ord_encoded_diamonds_df).transform(ord_encoded_diamonds_df)\n\nnp.array(transformed_diamonds_df.columns)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8daf2253-dfb1-4192-a9f9-43967262e0b9",
   "metadata": {
    "name": "cell13",
    "collapsed": false
   },
   "source": "Finally, we can also build out a full preprocessing Pipeline.\nThis will be useful for both the ML training & inference steps to have standarized feature transformations.\n"
  },
  {
   "cell_type": "code",
   "id": "81ea6002-d444-4e95-b9f1-61d401bc2c81",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": "# Categorize all the features for processing\nCATEGORICAL_COLUMNS = [\"CUT\", \"COLOR\", \"CLARITY\"]\nCATEGORICAL_COLUMNS_OE = [\"CUT_OE\", \"COLOR_OE\", \"CLARITY_OE\"] # To name the ordinal encoded columns\nNUMERICAL_COLUMNS = [\"CARAT\", \"DEPTH\", \"TAB_PCT\", \"X\", \"Y\", \"Z\"]\n\ncategories = {\n    \"CUT\": np.array([\"IDEAL\", \"PREMIUM\", \"VERY_GOOD\", \"GOOD\", \"FAIR\"]),\n    \"CLARITY\": np.array([\"IF\", \"VVS1\", \"VVS2\", \"VS1\", \"VS2\", \"SI1\", \"SI2\", \"I1\", \"I2\", \"I3\"]),\n    \"COLOR\": np.array(['D', 'E', 'F', 'G', 'H', 'I', 'J']),\n}",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5dbbfda3-f1e3-4427-bd4f-744ba0e6fb34",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": "# Categorize all the features for processing\nCATEGORICAL_COLUMNS = [\"CUT\", \"COLOR\", \"CLARITY\"]\nCATEGORICAL_COLUMNS_OE = [\"CUT_OE\", \"COLOR_OE\", \"CLARITY_OE\"]\nNUMERICAL_COLUMNS = [\"CARAT\", \"DEPTH\", \"TAB\", \"X\", \"Y\", \"Z\"]\n\n# Update categories to match actual values in the data\ncategories = {\n    \"CUT\": np.array([\"Fair\", \"Good\", \"Very Good\", \"Premium\", \"Ideal\"]),\n    \"CLARITY\": np.array([\"IF\", \"VVS1\", \"VVS2\", \"VS1\", \"VS2\", \"SI1\", \"SI2\", \"I1\", \"I2\", \"I3\"]),\n    \"COLOR\": np.array(['D', 'E', 'F', 'G', 'H', 'I', 'J'])\n}\n\n# Build the pipeline\npreprocessing_pipeline = Pipeline(\n    steps=[\n            (\n                \"OE\",\n                snowml.OrdinalEncoder(\n                    input_cols=CATEGORICAL_COLUMNS,\n                    output_cols=CATEGORICAL_COLUMNS_OE,\n                    categories=categories,\n                )\n            ),\n            (\n                \"MMS\",\n                snowml.MinMaxScaler(\n                    clip=True,\n                    input_cols=NUMERICAL_COLUMNS,\n                    output_cols=NUMERICAL_COLUMNS,\n                )\n            )\n    ]\n)\n\nPIPELINE_FILE = '/tmp/preprocessing_pipeline.joblib'\njoblib.dump(preprocessing_pipeline, PIPELINE_FILE)\n\ntransformed_diamonds_df = preprocessing_pipeline.fit(diamonds_df).transform(diamonds_df)\ntransformed_diamonds_df\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a1f3492-55d3-4be4-936e-f5ae2ebc3108",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": "session.sql(\"CREATE STAGE IF NOT EXISTS DIAMONDS\").collect()\n\nsession.file.put(PIPELINE_FILE, \"@DIAMONDS\", overwrite=True)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a6c1f175-55db-4267-9de4-29f8cf624e1c",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": "# Categorize all the features for modeling\nCATEGORICAL_COLUMNS = [\"CUT\", \"COLOR\", \"CLARITY\"]\nCATEGORICAL_COLUMNS_OE = [\"CUT_OE\", \"COLOR_OE\", \"CLARITY_OE\"] # To name the ordinal encoded columns\nNUMERICAL_COLUMNS = [\"CARAT\", \"DEPTH\", \"TAB\", \"X\", \"Y\", \"Z\"]\n\nLABEL_COLUMNS = ['PRICE']\nOUTPUT_COLUMNS = ['PREDICTED_PRICE']",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f68d3e04-08a7-4d06-905b-c32860f8bf43",
   "metadata": {
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": "session.file.get('@DIAMONDS/preprocessing_pipeline.joblib.gz', '/tmp')\nPIPELINE_FILE = '/tmp/preprocessing_pipeline.joblib.gz'\npreprocessing_pipeline = joblib.load(PIPELINE_FILE)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9fc2ae2f-1acc-485d-a64d-ffcc0ecc560b",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": "# Split the data into train and test sets\ndiamonds_train_df, diamonds_test_df = diamonds_df.random_split(weights=[0.9, 0.1], seed=0)\n\n# Run the train and test sets through the Pipeline object we defined earlier\ntrain_df = preprocessing_pipeline.fit(diamonds_train_df).transform(diamonds_train_df)\ntest_df = preprocessing_pipeline.transform(diamonds_test_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7d07346a-02d4-4b9e-a0c7-8852d919e7dd",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": "# Define the XGBRegressor\nregressor = XGBRegressor(\n    input_cols=CATEGORICAL_COLUMNS_OE+NUMERICAL_COLUMNS,\n    label_cols=LABEL_COLUMNS,\n    output_cols=OUTPUT_COLUMNS\n)\n\n# Train\nregressor.fit(train_df)\n\n# Predict\nresult = regressor.predict(test_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "10458eff-35ac-4a91-b506-b397be4e26f9",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": "regressor.predict(test_df[CATEGORICAL_COLUMNS_OE+NUMERICAL_COLUMNS].to_pandas())\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c17dd2f-5cee-44b4-a61b-c7aa92d67651",
   "metadata": {
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": "mape = mean_absolute_percentage_error(df=result, \n                                        y_true_col_names=\"PRICE\", \n                                        y_pred_col_names=\"PREDICTED_PRICE\")\n\nresult.select(\"PRICE\", \"PREDICTED_PRICE\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "65837510-3e7f-4d94-a48b-d6126626eb6c",
   "metadata": {
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": "print(f\"Mean absolute percentage error: {mape}\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c1a9778e-1ebf-4f42-a2c6-2f3667fd391d",
   "metadata": {
    "language": "python",
    "name": "cell24"
   },
   "outputs": [],
   "source": "g = sns.relplot(data=result[\"PRICE\", \"PREDICTED_PRICE\"].to_pandas().astype(\"float64\"), x=\"PRICE\", y=\"PREDICTED_PRICE\", kind=\"scatter\")\ng.ax.axline((0,0), slope=1, color=\"r\")\n\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c17a0be1-3800-4f84-bd33-e2b64fbfa662",
   "metadata": {
    "language": "python",
    "name": "cell25"
   },
   "outputs": [],
   "source": "grid_search = GridSearchCV(\n    estimator=XGBRegressor(),\n    param_grid={\n        \"n_estimators\":[100, 200, 300, 400, 500],\n        \"learning_rate\":[0.1, 0.2, 0.3, 0.4, 0.5],\n    },\n    n_jobs = -1,\n    scoring=\"neg_mean_absolute_percentage_error\",\n    input_cols=CATEGORICAL_COLUMNS_OE+NUMERICAL_COLUMNS,\n    label_cols=LABEL_COLUMNS,\n    output_cols=OUTPUT_COLUMNS\n)\n\n# Train\ngrid_search.fit(train_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf18e455-585b-483e-b4b6-8cd97abffaa0",
   "metadata": {
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": "# Analyze grid search results\ngs_results = grid_search.to_sklearn().cv_results_\nn_estimators_val = []\nlearning_rate_val = []\nfor param_dict in gs_results[\"params\"]:\n    n_estimators_val.append(param_dict[\"n_estimators\"])\n    learning_rate_val.append(param_dict[\"learning_rate\"])\nmape_val = gs_results[\"mean_test_score\"]*-1\n\ngs_results_df = pd.DataFrame(data={\n    \"n_estimators\":n_estimators_val,\n    \"learning_rate\":learning_rate_val,\n    \"mape\":mape_val})\n\nsns.relplot(data=gs_results_df, x=\"learning_rate\", y=\"mape\", hue=\"n_estimators\", kind=\"line\")\n\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70a25817-17ad-4b5d-b141-5ae9c2ce68ab",
   "metadata": {
    "language": "python",
    "name": "cell27"
   },
   "outputs": [],
   "source": "# Predict\nresult = grid_search.predict(test_df)\n\n# Analyze results\nmape = mean_absolute_percentage_error(df=result, \n                                        y_true_col_names=\"PRICE\", \n                                        y_pred_col_names=\"PREDICTED_PRICE\")\n\nresult.select(\"PRICE\", \"PREDICTED_PRICE\").show()\nprint(f\"Mean absolute percentage error: {mape}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "30af4bbf-2848-49d5-bec4-de324e451404",
   "metadata": {
    "language": "python",
    "name": "cell28"
   },
   "outputs": [],
   "source": "# Plot actual vs predicted \ng = sns.relplot(data=result[\"PRICE\", \"PREDICTED_PRICE\"].to_pandas().astype(\"float64\"), x=\"PRICE\", y=\"PREDICTED_PRICE\", kind=\"scatter\")\ng.ax.axline((0,0), slope=1, color=\"r\")\n\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e7e8d8f3-924a-419f-8249-9b7f64958823",
   "metadata": {
    "language": "python",
    "name": "cell29"
   },
   "outputs": [],
   "source": "optimal_model = grid_search.to_sklearn().best_estimator_\noptimal_n_estimators = grid_search.to_sklearn().best_estimator_.n_estimators\noptimal_learning_rate = grid_search.to_sklearn().best_estimator_.learning_rate\n\noptimal_mape = gs_results_df.loc[(gs_results_df['n_estimators']==optimal_n_estimators) &\n                                 (gs_results_df['learning_rate']==optimal_learning_rate), 'mape'].values[0]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cab7ba2d-0389-498b-8621-b5bb5669607a",
   "metadata": {
    "language": "python",
    "name": "cell30"
   },
   "outputs": [],
   "source": "# Get sample input data to pass into the registry logging function\nX = train_df.select(CATEGORICAL_COLUMNS_OE+NUMERICAL_COLUMNS).limit(100)\n\ndb = identifier._get_unescaped_name(session.get_current_database())\nschema = identifier._get_unescaped_name(session.get_current_schema())\n\n# Define model name\nmodel_name = \"DIAMONDS_PRICE_PREDICTION\"\n\n# Create a registry and log the model\nnative_registry = Registry(session=session, database_name=db, schema_name=schema)\n\n# Let's first log the very first model we trained\nmodel_ver = native_registry.log_model(\n    model_name=model_name,\n    version_name='V0',\n    model=regressor,\n    sample_input_data=X, # to provide the feature schema\n    options={\"enable_explainability\": True}\n)\n\n# Add evaluation metric\nmodel_ver.set_metric(metric_name=\"mean_abs_pct_err\", value=mape)\n\n# Add a description\nmodel_ver.comment = \"This is the first iteration of our Diamonds Price Prediction model. It is used for demo purposes.\"\n\n# Now, let's log the optimal model from GridSearchCV\nmodel_ver2 = native_registry.log_model(\n    model_name=model_name,\n    version_name='V1',\n    model=optimal_model,\n    sample_input_data=X, # to provide the feature schema\n    options={\"enable_explainability\": True}\n)\n\n# Add evaluation metric\nmodel_ver2.set_metric(metric_name=\"mean_abs_pct_err\", value=optimal_mape)\n\n# Add a description\nmodel_ver2.comment = \"This is the second iteration of our Diamonds Price Prediction model \\\n                        where we performed hyperparameter optimization.\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2d4b5e8b-f64a-46db-9b99-01157249591c",
   "metadata": {
    "language": "python",
    "name": "cell31"
   },
   "outputs": [],
   "source": "print('test')",
   "execution_count": null
  }
 ]
}